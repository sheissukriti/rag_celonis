AI Engineer Challenge â€“ Customer Support AI Assistant 

ğŸ“Œ Objective 

Your task is to develop an AI-powered customer support assistant that enhances responses 
using a foundational LLM and retrieval-augmented generation (RAG). 

This challenge will evaluate your ability to: 
 âœ… Implement RAG with a vector database (e.g. FAISS/ChromaDB). 
 âœ… Integrate an LLM-based response system. 
 âœ… Ensure explainability of model decisions. 
 âœ… Deploy a simple API for real-world usability. 

ğŸ“‚ Dataset 

We will use a public customer support dataset: 
 ğŸ“Œ Customer Support on Twitter 

This dataset contains customer queries and support responses. You can use this for 
retrieval-based response generation. 

ğŸ”¹ Challenge Tasks 

1âƒ£ Implement RAG-Based AI Assistant (4 hours) 

âœ… Use a foundation model (e.g., Mistral-7B, Llama-2, Falcon). 
âœ… Implement retrieval-augmented generation (RAG): 

â—  Retrieve relevant past queries & responses. 
â—  Use LLM to generate a response to a new support query. 

2âƒ£ Ensure Explainability & Evaluation (2 hours) 

âœ… (Preferred) Define an evaluation approach to assess response quality, correctness, and 
relevance. 

 
 
 âœ… (Optional) Implement basic explainability by highlighting retrieved documents or reasoning 
behind responses. 
 âœ… Be prepared to discuss explainability and evaluation strategies during the live demo. 

3âƒ£ API Deployment (2-4 hours) 

âœ… Develop a REST API (/generate_response) using FastAPI/Flask. 
âœ… Ensure it accepts user queries and returns AI-generated responses. 
âœ… Store responses in a mock database (JSON/SQLite) to log interactions for future reference. 
Alternatively, you can simply print the responses or save them in a CSV file - whatever works 
best for the purpose. 

ğŸ“¥ Submission Requirements 

You must submit the following: 
 âœ… GitHub/Code repository with clean, modular code. 
 âœ… API endpoint (if deployed) for live testing. 
 âœ… PPT (Template shared)/Short README explaining: 

â—  Approach taken 
â—  RAG implementation details 
â—  Explainability techniques 

 âœ… (Optional Bonus) 2-minute video demo. 

ğŸ† Evaluation Criteria 

Category 

Weight (%) 

Evaluation Focus 

RAG Implementation  40% 

Retrieval accuracy, LLM enhancement 

Explainability 

API Deployment 

Code Quality 

Innovation 

20% 

20% 

10% 

10% 

Reasoning  

Usability, efficiency 

Clean, structured code 

Enhancements (multi-turn, caching, 
integrations) 

 
 
 
 
ğŸ“Œ Example Queries for Testing 

Use the following queries to test your model: 

1âƒ£ "I ordered a laptop, but it arrived with a broken screen. What should I do?" 
2âƒ£ "I need help resetting my password." (Follow-up) "I didnâ€™t receive the reset link." 
3âƒ£ "My cat chewed my phone charger. Is this covered under warranty?" 
4âƒ£ "Why did you suggest contacting support?" (Checks explainability!) 

â³ Time Duration & Deadline 

ğŸ“… You have 1 week to complete this challenge. 
â³ Submission Deadline: [Insert Date - 7 days from today] 
ğŸ“© Share your GitHub/Code repo + API link(optional) with us via email. 

âœ… Final Report/PPT: Candidates must submit a summary report/ppt 24 hours before the 
panel presentation. 

We look forward to seeing your innovative solutions! ğŸš€ 

 
 
 
 
 
